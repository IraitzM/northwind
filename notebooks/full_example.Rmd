---
title: "Building a RDBMS for a retail business"
output: html_notebook
---

This is an [R Markdown](http://rmarkdown.rstudio.com) Notebook where several aspects involved on modeling a database will be explored.

For this notebook to work, one of the first things we will need to do is have a RDBMS system running. In particular, [PostgreSQL](https://www.postgresql.org/) will be used so you can download and install it or just user a docker image and instantiate an image for this demo using following commands:

To pull the image from the repository

* docker pull postgres

Container can be started, killed and restarted as many times as you want:

* docker run --name some-postgres -e POSTGRES_PASSWORD=mysecretpassword -p 5432:5432 -d postgres:13
* docker kill some-postgres
* docker restart some-postgres

And its local IP address found using inspect command so we can connect and work with it:

* docker inspect some-postgres

Next thing, a bunch of libraries will be needed to run our code.

```{r}
renv::restore()
```

Also, auxiliary functions to ease the tasks need to be loaded.

```{r}
source('../src/aux_functions.R')
```

We have the RDBMS up and running and all libraries loaded to start working. Lets first connect to the database.

```{r}
dhost <- 'localhost'

# Let's connect to our database
con <- DBI::dbConnect(RPostgres::Postgres(), 
                      user= 'postgres', 
                      password = 'mysecretpassword', 
                      host=dhost)

# List existing tables
list(con)
```

Ok, empty! Let's start creating our data schema so we can then support our business processes and manage the data they need and generate.

```{r}
# Customers
q <- 'CREATE TABLE customers (
    customerid bpchar NOT NULL,
    companyname character varying(40) NOT NULL,
    contactname character varying(30),
    contacttitle character varying(30),
    address character varying(60),
    city character varying(30),
    region character varying(30),
    postalcode character varying(10),
    country character varying(30),
    phone character varying(24),
    fax character varying(24)
);'
exec(con,q)
# List existing tables
list(con)
```

It works, lets do the rest.

```{r}
# Employees
q <- 'CREATE TABLE employees (
    employeeid smallint NOT NULL,
    lastname character varying(20) NOT NULL,
    firstname character varying(10) NOT NULL,
    title character varying(30),
    titleofcourtesy character varying(25),
    birthdate date,
    hiredate date,
    address character varying(60),
    city character varying(15),
    region character varying(15),
    postalcode character varying(10),
    country character varying(15),
    homephone character varying(24),
    extension character varying(4),
    photo bytea,
    notes text,
    reportsto smallint,
    photopath character varying(255)
);'
exec(con, q)

# Order details
q <- 'CREATE TABLE order_details (
    orderid smallint NOT NULL,
    productid smallint NOT NULL,
    unitprice real NOT NULL,
    quantity smallint NOT NULL,
    discount real NOT NULL
);'
exec(con, q)

# Orders
q <- 'CREATE TABLE orders (
    orderid smallint NOT NULL,
    customerid bpchar,
    employeeid smallint,
    orderdate date,
    requireddate date,
    shippeddate date,
    shipvia smallint,
    freight real
);'
exec(con, q)

# Products
q <- 'CREATE TABLE products (
    productid smallint NOT NULL,
    productname character varying(40) NOT NULL,
    supplierid smallint,
    categoryid smallint,
    quantityperunit character varying(20),
    unitprice real,
    unitsinstock smallint,
    unitsonorder smallint,
    reorderlevel smallint,
    discontinued integer NOT NULL
);'
exec(con, q)

# List existing tables
list(con)
```

So, once relations are there we can start putting the constraint that will help as have a consistent data model for our retail business. First the Primary Keys for our relations/tables.

```{r}
# Add PK to customers
q <-'ALTER TABLE ONLY customers
ADD CONSTRAINT pk_customers PRIMARY KEY (customerid);'
exec(con, q)

# Add PK to employees
q <-'ALTER TABLE ONLY employees
ADD CONSTRAINT pk_employees PRIMARY KEY (employeeid);'
exec(con, q)

# Add composed PK to order_details
q <-'ALTER TABLE ONLY order_details
ADD CONSTRAINT pk_order_details PRIMARY KEY (orderid, productid);'
exec(con, q)

# Add PK to orders
q <-'ALTER TABLE ONLY orders
ADD CONSTRAINT pk_orders PRIMARY KEY (orderid);'
exec(con, q)

# Add PK to products
q <-'ALTER TABLE ONLY products
ADD CONSTRAINT pk_products PRIMARY KEY (productid);'
exec(con, q)
```

Now let's relate the Keys found in the rest of the tables to the row the refer to.

```{r}
# Now relate FKs orders.customerid with customers
q <-'ALTER TABLE ONLY orders
ADD CONSTRAINT fk_orders_customers FOREIGN KEY (customerid) REFERENCES customers;'
exec(con, q)

# Now relate FKs orders.employeeid with employees
q <-'ALTER TABLE ONLY orders
ADD CONSTRAINT fk_orders_employees FOREIGN KEY (employeeid) REFERENCES employees;'
exec(con, q)

# Now relate FKs order_details.productid with products
q <-'ALTER TABLE ONLY order_details
ADD CONSTRAINT fk_order_details_products FOREIGN KEY (productid) REFERENCES products;'
exec(con, q)

# Now relate FKs order_details.orderid with orders
q <-'ALTER TABLE ONLY order_details
ADD CONSTRAINT fk_order_details_orders FOREIGN KEY (orderid) REFERENCES orders;'
exec(con, q)
```

Good! Our schema should be complete by now.

Now that our model is complete we can use it for some data manipulation. Inserting a customer for example.

```{r}
exec(con, "INSERT INTO customers(customerid, companyname) VALUES (1, 'Deusto')")
```

And show how our information is there.

```{r}
query(con, "SELECT * FROM customers")
```
Update the information on that tuple.

```{r}
exec(con, "UPDATE customers SET contactname = 'Iraitz' WHERE companyname = 'Deusto'")
query(con, "SELECT * FROM customers")
```
And check if our constraints do their work.

```{r}
exec(con, "INSERT INTO customers(customerid, companyname) VALUES (1, 'Deusto')")
```

Or just delete the information.

```{r}
exec(con, "DELETE FROM customers WHERE companyname = 'Deusto'")
query(con, "SELECT * FROM customers")
```

We can just bulk load some information so we can test also RDBMS computing capabilities.

```{r}
load <- function(con, fname){
  df <- read.csv(paste0("../data/", fname, ".csv"), as.is=T, sep = ',')
  colnames(df)<-tolower(colnames(df))
  dbAppendTable(con, fname, df)
}

load(con, "customers")
load(con, "employees")
load(con, "products")
load(con, "orders")
load(con, "order_details")

```
```{r}
query(con, "SELECT * FROM employees WHERE region = 'NULL'")
```

```{r}
# Or ask it to compute something
query(con, "SELECT count(distinct companyName) AS count FROM customers")
```
```{r}
# Thanks to relational algebra we can combine information from table
# and ask for computation
query(con, "SELECT e.firstname, count(orderid) as sales
FROM employees e
INNER JOIN orders o ON o.employeeid = e.employeeid
GROUP BY e.firstname
ORDER BY 2 DESC")
```
So, we have the model and the data the only thing missing then is the business process. We can just try to envision how a SALES process would be. Steps would be:

* We should identify the customer
* Verify that the product exists
* Create a new order
* Associate products with orders

```{r}
# Lets do a sale, we will create a function that does the following
sale <- function(who, what, price, quantity, e_id){
  c_id <- query(con, paste0("SELECT customerid 
                                     FROM customers 
                                     WHERE companyname = '",who,"'"))
  
  # Let's see if there is product stock
  p_id <- query(con, paste0("SELECT productid 
                                     FROM products 
                                     WHERE productname = '",what,"'
                                     AND discontinued = 0"))
  
  # We get the next order id
  o_id <- query(con, "SELECT MAX(orderid)+1 AS orderid FROM orders")
  
  # We insert a new order
  insert <- paste0("INSERT INTO orders(orderid, customerid, employeeid, orderdate) VALUES ("
                   ,o_id$orderid,",'"
                   ,c_id$customerid,"',"
                   ,e_id,","
                   ,"'2020-11-09 00:00:00'",")"
  )
  exec(con, insert)
  
  # We take the quantity out of stock
  exec(con, paste0("UPDATE products SET unitsinstock = unitsinstock - ",quantity," WHERE productid = ", p_id))
  
  # Finally we do insert the order details to associate product to the order
  insert <- paste0("INSERT INTO order_details VALUES ("
                   ,o_id$orderid,","
                   ,p_id$productid,","
                   ,price,","
                   ,quantity,",0)"
  )
  exec(con, insert)
  
  return(o_id$orderid)
}
```

And use that function to make a sale.

```{r}
#  Customer : Frankenversand
#  Product : Geitost
#  Price : Product sale price
#  Quantity
#  Employee : who sold it
o_id <- sale("Frankenversand", "Geitost", 0.10, 1, 5)
query(con, paste0("SELECT * FROM order_details WHERE orderid = ",o_id))
```
We can check the stock.

```{r}
u_s <- query(con, "SELECT unitsinstock FROM products WHERE productname = 'Geitost'")$unitsinstock
u_s
```
What happens if we buy more than we can sell?

```{r}
# What happens if we go out of stock?
o_id <- sale("Frankenversand", "Geitost", 0.10, u_s+5, 5)
query(con, "SELECT productid, productname, unitsinstock FROM products WHERE productname = 'Geitost'")
```

Oh my! Did we brake something? Well, that's the issue with transactions. We need to ensure that business processes work fine.

```{r}
exec(con, 
"CREATE OR REPLACE PROCEDURE sale(who text, what text, price float, quantity int, e_id int)
   LANGUAGE 'plpgsql'
   AS $$
DECLARE
       c_id text;
       p_id int;
       o_id int;
       units int;
BEGIN 

  SELECT customerid INTO c_id FROM customers WHERE companyname = $1;
  IF c_id IS NULL THEN 
    RAISE EXCEPTION 'Cannot find customer %', $1; 
  END IF; 
  
  SELECT productid INTO p_id 
    FROM products 
    WHERE productname = $2 
      AND discontinued = 0;
  IF p_id IS NULL THEN 
    RAISE EXCEPTION 'Cannot find product %', $2; 
  END IF; 
  
  SELECT MAX(orderid)+1 INTO o_id FROM orders;
  
  INSERT INTO orders(orderid, customerid, employeeid, orderdate) VALUES (o_id, c_id, e_id, '2020-11-09 00:00:00');
  
  UPDATE products SET unitsinstock = unitsinstock - $4 WHERE productid = p_id;
  
  INSERT INTO order_details VALUES (o_id,p_id,$3,$4,0);
  
  SELECT unitsinstock INTO units FROM products 
    WHERE productname = $2;
  
  IF units < 0 THEN
    RAISE NOTICE 'Not enough units in stock';
    ROLLBACK;
  END IF;
END;
$$;")
```

With those error controls one guaranties that the operations work fine or give some information about the potential problems while keeping the DBs in a correct status.

```{r}
dbExecute(con, "CALL sale('Iraitz', 'Geitost', 0.10, 1, 5)")
```

```{r}
dbExecute(con, "CALL sale('Frankenversand', 'Harddrive', 0.10, 1, 5)")
```
```{r}
dbExecute(con, "CALL sale('Frankenversand', 'Geitost', 0.10, 1000, 5)")
```

```{r}
exec(con, "UPDATE products SET unitsinstock = 10 WHERE productname = 'Geitost'")
```

```{r}
dbExecute(con, "CALL sale('Frankenversand', 'Geitost', 0.10, 10, 5)")
```
```{r}
query(con, "SELECT unitsinstock FROM products WHERE productname = 'Geitost'")
```

Now that we have our information it would be nice to have a dimensional model we could use for reporting, for example. Given that our model is simple enough, dimensions won't require much work.

```{r}
query(con, "CREATE TABLE customer_dim AS SELECT customerid, companyname, region, city
                          FROM customers")
```

```{r}
query(con, "CREATE TABLE order_dim AS SELECT orderid, orderdate, shipvia, freight
                          FROM orders")
```
```{r}
query(con, "CREATE TABLE product_dim AS SELECT productid, productname, unitprice, unitsinstock
                          FROM products")
```

And our facts table too.
```{r}
query(con, "CREATE TABLE orderline_fact AS SELECT od.*, customerid, orderdate
                          FROM orders o
                          INNER JOIN order_details od ON od.orderid = o.orderid")
```

And set relationships between those.

```{r}
# Add PK to customer_dim
q <-'ALTER TABLE ONLY customer_dim
ADD CONSTRAINT pk_customer PRIMARY KEY (customerid);'
exec(con, q)

# Add PK to product_dim
q <-'ALTER TABLE ONLY product_dim
ADD CONSTRAINT pk_product PRIMARY KEY (productid);'
exec(con, q)

# Add PK to order_dim
q <-'ALTER TABLE ONLY order_dim
ADD CONSTRAINT pk_order PRIMARY KEY (orderid);'
exec(con, q)
```

```{r}
# set compound key
q <-'ALTER TABLE ONLY orderline_fact
ADD CONSTRAINT pk_olfact PRIMARY KEY (customerid, productid, orderid);'
exec(con, q)
```

```{r}
# Now relate FKs
q <-'ALTER TABLE ONLY orderline_fact
ADD CONSTRAINT fk_olfact_customers FOREIGN KEY (customerid) REFERENCES customer_dim;'
exec(con, q)

q <-'ALTER TABLE ONLY orderline_fact
ADD CONSTRAINT fk_olfact_orders FOREIGN KEY (orderid) REFERENCES order_dim;'
exec(con, q)

q <-'ALTER TABLE ONLY orderline_fact
ADD CONSTRAINT fk_olfact_products FOREIGN KEY (productid) REFERENCES product_dim;'
exec(con, q)
```

Now we could ETL on a nightly batch the information from operational sources to be updated into our datawarehouse and have it available for reporting first thing in the morning. We could launch queries like the following in order to report sales.

```{r}
query(con, "SELECT date_part('month', orderdate) AS month, customerid AS client, productid AS product, count(*) AS howmany FROM orderline_fact GROUP BY month, client, product")
```
And user dimensions when more information is needed.

```{r}
query(con, "SELECT date_part('month', orderdate) AS month, customerid AS client, p.productname AS product, count(*) AS howmany FROM orderline_fact olf
      JOIN product_dim p ON p.productid = olf.productid GROUP BY month, client, product")
```

From there, if our model was big enough we could require some cube construction, that should be easy to design. Let's do an hypercube with four dimensions (year, month, client and product)

```{r}
# Dim#1 -> year
# Dim#2 -> month
# Dim#3 -> productid
# Dim#4 -> customerid
# Measure -> count(*)
cube <- query(con, "SELECT date_part('year', orderdate) AS year, date_part('month', orderdate) AS month, 
                                    customerid AS client, 
                                    productid AS product, 
                                    count(*) AS howmany
                            FROM orderline_fact
                            GROUP BY year, month, client, product")
storeTable(con, cube, "productivity")
```

From there it is much simpler to derive complex questions that should run fast enough.

```{r}
# Two most productive months
query(con, "SELECT month, sum(howmany) 
                           FROM productivity 
                           GROUP BY month
                           ORDER BY 2 DESC
                           LIMIT 2")
```

```{r}
# Three most productive months-client
query(con, "SELECT month, client, sum(howmany) 
                           FROM productivity 
                           GROUP BY month, client
                           ORDER BY 3 DESC
                           LIMIT 3")
```

Lets see how price affects the products we sell.

```{r}
# Dim#1 -> yearmonth
# Dim#2 -> unitprice : low (< 5), medium (>= 5 AND < 30), high ( >= 30 )
# Dim#3 -> unitprice
# Dim#4 -> quantity
# Measure -> total

cube <- query(con, "SELECT date_part('year', orderdate)::TEXT || date_part('month', orderdate)::TEXT AS month, 
                                    CASE WHEN unitprice < 5 THEN 'low'
                                         WHEN unitprice >= 30 THEN 'high'
                                         ELSE 'medium' 
                                    END AS pricerange,
                                    unitprice AS price,
                                    quantity AS quantity, 
                                    (unitprice*quantity) AS total
                            FROM orderline_fact
                            GROUP BY month, price, quantity")
storeTable(con, cube, "salesprice")
```


Let's clean everything up and disconnect from the database.

```{r}
clearDB(con)
DBI::dbDisconnect(con)
```

